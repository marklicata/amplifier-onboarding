{
  "id": "12_approval_gates",
  "title": "Approval Gates in Action",
  "tier": 4,
  "category": "Real-World",
  "description": "Approval Gates in Action",
  "estimatedTimeMinutes": 5,
  "minAudience": "developers",
  "isFeatured": false,
  "difficulty": "advanced",
  "tags": [
    "tools",
    "composition"
  ],
  "githubUrl": "https://github.com/microsoft/amplifier-foundation/blob/main/examples/12_approval_gates.py",
  "content": {
    "everyone": {
      "title": "Approval Gates in Action",
      "valueProposition": "Learn to work with AI agents",
      "howItWorks": [
        "Set up your AI environment",
        "Configure the agent with the right capabilities",
        "Run the example and see results",
        "Understand what happened"
      ],
      "whatYouGet": [
        "Working example you can run",
        "Clear understanding of the concept",
        "Foundation for building more"
      ]
    },
    "developers": {
      "title": "12_approval_gates.py - Approval Gates in Action",
      "valueProposition": "",
      "howItWorks": "",
      "keyConcepts": [
        "Amplifier bundle system",
        "Module composition",
        "Session execution"
      ],
      "codeOverview": {
        "structure": [
          "Load foundation and provider bundles",
          "Execute prompts and get responses"
        ],
        "keyFunctions": [
          {
            "name": "load_bundle",
            "description": "Loads a bundle from path or URL",
            "usage": "load_bundle(str(foundation_path)"
          },
          {
            "name": "execute",
            "description": "Executes a prompt",
            "usage": "execute(prompt)"
          },
          {
            "name": "mount",
            "description": "Registers a custom tool or component",
            "usage": "mount(...)"
          }
        ]
      },
      "codeSnippet": "async def main():\n    \"\"\"Run interactive demo menu.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"\ud83d\ude80 Approval Gates in Action\")\n    print(\"=\" * 80)\n    print(\"\\nVALUE: Shows how Amplifier provides safety and control over AI actions\")\n    print(\"AUDIENCE: Security-conscious teams, regulated industries\")\n    print(\"\\nWhat this demonstrates:\")\n    print(\"  - Human-in-the-loop approval for AI actions\")\n    print(\"  - Granular control over which tools require approval\")\n    print(\"  - Audit trail of all approval decisions\")\n    print(\"  - Flexible approval policies (always ask, auto-approve, selective)\")\n\n    scenarios = [\n        (\"File Operations (approve each write)\", scenario_file_operations),"
    },
    "experts": {
      "title": "12_approval_gates.py - Approval Gates in Action",
      "complexity": "Tier 4 - Real-World Applications",
      "sourceUrl": "https://github.com/microsoft/amplifier-foundation/blob/main/examples/12_approval_gates.py",
      "architecture": "",
      "fullCode": "#!/usr/bin/env python3\n\"\"\"\nExample 12: Approval Gates in Action\n=====================================\n\nAUDIENCE: Everyone - security-conscious teams, regulated industries, cautious adopters\nVALUE: Shows how Amplifier provides safety and control over AI actions\nPATTERN: Interactive approval flow with granular control\n\nWhat this demonstrates:\n  - Safety mechanisms and human-in-the-loop control\n  - Granular approval for sensitive operations\n  - Audit trail of approved/rejected actions\n  - Different approval strategies (always ask, auto-approve certain tools, etc.)\n\nWhen you'd use this:\n  - Production environments where AI shouldn't act without oversight\n  - Regulated industries (healthcare, finance) requiring human approval\n  - Learning/training scenarios where you want to see what AI plans to do\n  - High-stakes operations (deployments, data modifications, API calls)\n\"\"\"\n\nimport asyncio\nfrom pathlib import Path\nfrom typing import Any\nfrom typing import Literal\n\nfrom amplifier_core import AmplifierSession\nfrom amplifier_foundation import load_bundle\n\n# ============================================================================\n# Custom Approval System Implementation\n# ============================================================================\n\n\nclass InteractiveApprovalSystem:\n    \"\"\"\n    Approval system that prompts the user interactively.\n\n    Implements ApprovalSystem protocol for AmplifierSession.\n\n    Features:\n    - Shows prompt and available options\n    - Allows approve/reject/approve-all decisions\n    - Maintains audit trail of decisions\n    - Supports auto-approval rules\n    \"\"\"\n\n    def __init__(self, auto_approve_tools: list[str] | None = None):\n        self.auto_approve_tools = auto_approve_tools or []\n        self.audit_trail: list[dict[str, Any]] = []\n        self.approve_all = False\n\n    async def request_approval(\n        self, prompt: str, options: list[str], timeout: float, default: Literal[\"allow\", \"deny\"]\n    ) -> str:\n        \"\"\"Request approval from the user.\n\n        Args:\n            prompt: Question to ask user\n            options: Available choices\n            timeout: Seconds to wait for response\n            default: Action to take on timeout\n\n        Returns:\n            Selected option string (one of options)\n        \"\"\"\n        # Check if auto-approve is enabled\n        if self.approve_all:\n            self._log_decision(prompt, options[0] if options else \"allow\", auto=True)\n            return options[0] if options else \"allow\"\n\n        # Interactive approval\n        print(\"\\n\" + \"=\" * 80)\n        print(\"\ud83d\udea8 APPROVAL REQUIRED\")\n        print(\"=\" * 80)\n        print(f\"\\n\ud83d\udccb {prompt}\")\n        print(f\"\\n\u23f1\ufe0f  Timeout: {timeout}s (default: {default})\")\n\n        print(\"\\n\" + \"-\" * 80)\n        print(\"Options:\")\n        for i, option in enumerate(options, 1):\n            print(f\"  [{i}] {option}\")\n        print(\"  [a] Approve ALL remaining requests\")\n        print(\"-\" * 80)\n\n        while True:\n            choice = input(\"\\nYour decision: \").strip().lower()\n\n            if choice == \"a\":\n                self.approve_all = True\n                selected = options[0] if options else \"allow\"\n                print(\"\\n\u2705 All future requests will be auto-approved\")\n                self._log_decision(prompt, selected, auto=False)\n                return selected\n\n            try:\n                idx = int(choice) - 1\n                if 0 <= idx < len(options):\n                    selected = options[idx]\n                    self._log_decision(prompt, selected, auto=False)\n                    return selected\n            except ValueError:\n                pass\n\n            print(f\"\u274c Invalid choice. Please enter 1-{len(options)} or 'a'.\")\n\n    def _log_decision(self, prompt: str, decision: str, auto: bool) -> None:\n        \"\"\"Log approval decision to audit trail.\"\"\"\n        self.audit_trail.append(\n            {\n                \"prompt\": prompt,\n                \"decision\": decision,\n                \"auto\": auto,\n            }\n        )\n\n    def print_audit_trail(self) -> None:\n        \"\"\"Print the audit trail of all approval decisions.\"\"\"\n        if not self.audit_trail:\n            print(\"\\n\ud83d\udcca No approval requests\")\n            return\n\n        print(\"\\n\" + \"=\" * 80)\n        print(\"\ud83d\udcca AUDIT TRAIL\")\n        print(\"=\" * 80)\n        for i, entry in enumerate(self.audit_trail, 1):\n            auto_label = \" (auto)\" if entry[\"auto\"] else \"\"\n            print(f\"\\n{i}. {entry['decision']}{auto_label}\")\n            print(f\"   Prompt: {entry['prompt']}\")\n\n\n# ============================================================================\n# Demo Scenarios\n# ============================================================================\n\n\nasync def scenario_file_operations():\n    \"\"\"\n    Scenario: File operations requiring approval.\n\n    Demonstrates approval for potentially destructive operations.\n    \"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"SCENARIO 1: File Operations with Approval\")\n    print(\"=\" * 80)\n    print(\"\\nThis scenario asks the AI to create and modify files.\")\n    print(\"You'll be prompted to approve each file operation.\")\n    print(\"\\nTask: Create a simple Python module with tests\")\n    print(\"-\" * 80)\n\n    # Load foundation bundle\n    foundation_path = Path(__file__).parent.parent\n    foundation = await load_bundle(str(foundation_path))\n\n    # Create approval system (require approval for all tools)\n    approval_system = InteractiveApprovalSystem()\n\n    # Compose mount plan\n    mount_plan = foundation.to_mount_plan()\n\n    # Create session with approval system\n    session = AmplifierSession(\n        config=mount_plan,\n        approval_system=approval_system,\n    )\n\n    await session.initialize()\n\n    prompt = \"\"\"Create a simple Python module in the current directory:\n\n1. Create a file called `calculator.py` with basic add/subtract functions\n2. Create a file called `test_calculator.py` with tests for those functions\n\nPlease proceed step by step.\"\"\"\n\n    try:\n        print(\"\\n\u23f3 Executing task...\")\n        await session.execute(prompt)\n        print(\"\\n\" + \"=\" * 80)\n        print(\"\u2705 Task completed\")\n        print(\"=\" * 80)\n\n    finally:\n        approval_system.print_audit_trail()\n        await session.cleanup()\n\n\nasync def scenario_selective_approval():\n    \"\"\"\n    Scenario: Auto-approve safe tools, require approval for risky ones.\n\n    Demonstrates selective approval policies.\n    \"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"SCENARIO 2: Selective Auto-Approval\")\n    print(\"=\" * 80)\n    print(\"\\nThis scenario auto-approves 'safe' tools (read operations)\")\n    print(\"but requires approval for 'risky' tools (write operations).\")\n    print(\"\\nTask: Analyze project structure and create a README\")\n    print(\"-\" * 80)\n\n    # Load foundation bundle\n    foundation_path = Path(__file__).parent.parent\n    foundation = await load_bundle(str(foundation_path))\n\n    # Create approval system (auto-approve read-only tools)\n    approval_system = InteractiveApprovalSystem(auto_approve_tools=[\"tool-read-file\", \"tool-glob\", \"tool-grep\"])\n\n    # Compose mount plan\n    mount_plan = foundation.to_mount_plan()\n\n    # Create session with approval system\n    session = AmplifierSession(\n        config=mount_plan,\n        approval_system=approval_system,\n    )\n\n    await session.initialize()\n\n    prompt = \"\"\"Analyze the current project structure:\n\n1. Use glob to find all Python files\n2. Read a few key files to understand the project\n3. Create a simple README.md summarizing the project\n\nThe read operations should auto-approve, but you'll need approval for the write.\"\"\"\n\n    try:\n        print(\"\\n\u23f3 Executing task...\")\n        await session.execute(prompt)\n        print(\"\\n\" + \"=\" * 80)\n        print(\"\u2705 Task completed\")\n        print(\"=\" * 80)\n\n    finally:\n        approval_system.print_audit_trail()\n        await session.cleanup()\n\n\nasync def scenario_api_calls():\n    \"\"\"\n    Scenario: Require approval for external API calls.\n\n    Demonstrates approval for operations that affect external systems.\n    \"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"SCENARIO 3: External API Call Approval\")\n    print(\"=\" * 80)\n    print(\"\\nThis scenario requires approval for any bash commands\")\n    print(\"(which could make network requests or modify system state).\")\n    print(\"\\nTask: Check system information\")\n    print(\"-\" * 80)\n\n    # Load foundation bundle\n    foundation_path = Path(__file__).parent.parent\n    foundation = await load_bundle(str(foundation_path))\n\n    # Create approval system\n    approval_system = InteractiveApprovalSystem()\n\n    # Compose mount plan\n    mount_plan = foundation.to_mount_plan()\n\n    # Create session with approval system\n    session = AmplifierSession(\n        config=mount_plan,\n        approval_system=approval_system,\n    )\n\n    await session.initialize()\n\n    prompt = \"\"\"Run these system commands to gather information:\n\n1. Check Python version: python --version\n2. Check current directory: pwd\n3. List files in current directory: ls -la\n\nEach bash command will require approval.\"\"\"\n\n    try:\n        print(\"\\n\u23f3 Executing task...\")\n        await session.execute(prompt)\n        print(\"\\n\" + \"=\" * 80)\n        print(\"\u2705 Task completed\")\n        print(\"=\" * 80)\n\n    finally:\n        approval_system.print_audit_trail()\n        await session.cleanup()\n\n\n# ============================================================================\n# Interactive Menu\n# ============================================================================\n\n\nasync def main():\n    \"\"\"Run interactive demo menu.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"\ud83d\ude80 Approval Gates in Action\")\n    print(\"=\" * 80)\n    print(\"\\nVALUE: Shows how Amplifier provides safety and control over AI actions\")\n    print(\"AUDIENCE: Security-conscious teams, regulated industries\")\n    print(\"\\nWhat this demonstrates:\")\n    print(\"  - Human-in-the-loop approval for AI actions\")\n    print(\"  - Granular control over which tools require approval\")\n    print(\"  - Audit trail of all approval decisions\")\n    print(\"  - Flexible approval policies (always ask, auto-approve, selective)\")\n\n    scenarios = [\n        (\"File Operations (approve each write)\", scenario_file_operations),\n        (\"Selective Approval (auto-approve reads)\", scenario_selective_approval),\n        (\"API/System Calls (approve bash commands)\", scenario_api_calls),\n    ]\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"Choose a scenario:\")\n    print(\"=\" * 80)\n    for i, (name, _) in enumerate(scenarios, 1):\n        print(f\"  {i}. {name}\")\n    print(\"  q. Quit\")\n    print(\"-\" * 80)\n\n    choice = input(\"\\nYour choice: \").strip().lower()\n\n    if choice == \"q\":\n        print(\"\\n\ud83d\udc4b Goodbye!\")\n        return\n\n    try:\n        idx = int(choice) - 1\n        if 0 <= idx < len(scenarios):\n            _, scenario_func = scenarios[idx]\n            await scenario_func()\n        else:\n            print(\"\\n\u274c Invalid choice\")\n    except ValueError:\n        print(\"\\n\u274c Invalid choice\")\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"\ud83d\udca1 KEY TAKEAWAYS\")\n    print(\"=\" * 80)\n    print(\"\"\"\n1. **Safety First**: Approval gates prevent AI from taking actions without oversight\n2. **Flexible Policies**: Auto-approve safe operations, require approval for risky ones\n3. **Audit Trail**: Every decision is logged for compliance and debugging\n4. **Production-Ready**: Use this pattern in production to maintain control\n5. **Granular Control**: Approve/reject individual operations, not all-or-nothing\n\n**When to use approval gates:**\n- Production environments with sensitive operations\n- Regulated industries requiring human oversight\n- Training environments to understand AI behavior\n- High-stakes operations (deployments, financial transactions)\n- Any time you want explicit control over AI actions\n\"\"\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
      "advancedOptions": {
        "provider": [
          "anthropic-sonnet",
          "anthropic-opus",
          "openai-gpt4"
        ],
        "streaming": false,
        "hooks": []
      }
    }
  },
  "execution": {
    "requiresInput": true,
    "defaultPrompt": null,
    "estimatedDuration": "2-5 seconds",
    "prerequisites": [
      "ANTHROPIC_API_KEY environment variable"
    ]
  }
}