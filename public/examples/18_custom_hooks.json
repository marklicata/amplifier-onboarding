{
  "id": "18_custom_hooks",
  "title": "Custom Hook Library",
  "tier": 4,
  "category": "Real-World",
  "description": "Custom Hook Library",
  "estimatedTimeMinutes": 5,
  "minAudience": "developers",
  "isFeatured": false,
  "difficulty": "advanced",
  "tags": [
    "tools",
    "composition",
    "hooks"
  ],
  "githubUrl": "https://github.com/microsoft/amplifier-foundation/blob/main/examples/18_custom_hooks.py",
  "content": {
    "everyone": {
      "title": "Custom Hook Library",
      "valueProposition": "Learn to work with AI agents",
      "howItWorks": [
        "Set up your AI environment",
        "Configure the agent with the right capabilities",
        "Run the example and see results",
        "Understand what happened"
      ],
      "whatYouGet": [
        "Working example you can run",
        "Clear understanding of the concept",
        "Foundation for building more"
      ]
    },
    "developers": {
      "title": "18_custom_hooks.py - Custom Hook Library",
      "valueProposition": "",
      "howItWorks": "",
      "keyConcepts": [
        "Amplifier bundle system",
        "Module composition",
        "Session execution"
      ],
      "codeOverview": {
        "structure": [
          "Load foundation and provider bundles",
          "Execute prompts and get responses"
        ],
        "keyFunctions": [
          {
            "name": "load_bundle",
            "description": "Loads a bundle from path or URL",
            "usage": "load_bundle(str(foundation_path)"
          },
          {
            "name": "compose",
            "description": "Combines multiple bundles",
            "usage": "compose(...)"
          },
          {
            "name": "execute",
            "description": "Executes a prompt",
            "usage": "execute(prompt)"
          },
          {
            "name": "mount",
            "description": "Registers a custom tool or component",
            "usage": "mount(...)"
          }
        ]
      },
      "codeSnippet": "async def main():\n    \"\"\"Run interactive demo menu.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"\ud83c\udfa3 Custom Hook Library\")\n    print(\"=\" * 80)\n    print(\"\\nVALUE: Build reusable hooks for production applications\")\n    print(\"AUDIENCE: Developers building with Amplifier\")\n    print(\"\\nWhat this demonstrates:\")\n    print(\"  - Performance monitoring and metrics\")\n    print(\"  - Real-time cost tracking\")\n    print(\"  - Audit logging for compliance\")\n    print(\"  - Composing multiple hooks\")\n\n    scenarios = [\n        (\"Performance Monitoring\", scenario_performance_monitoring),"
    },
    "experts": {
      "title": "18_custom_hooks.py - Custom Hook Library",
      "complexity": "Tier 4 - Real-World Applications",
      "sourceUrl": "https://github.com/microsoft/amplifier-foundation/blob/main/examples/18_custom_hooks.py",
      "architecture": "",
      "fullCode": "#!/usr/bin/env python3\n\"\"\"\nExample 18: Custom Hook Library\n================================\n\nAUDIENCE: Developers building production Amplifier applications\nVALUE: Shows how to create reusable, composable hooks for common patterns\nPATTERN: Hook library, middleware patterns, aspect-oriented programming\n\nWhat this demonstrates:\n  - Building custom hooks for observability and control\n  - Composing multiple hooks together\n  - Performance monitoring and metrics collection\n  - Error tracking and recovery\n  - Audit logging and compliance\n\nWhen you'd use this:\n  - Production applications needing observability\n  - Building reusable components across projects\n  - Implementing cross-cutting concerns (logging, metrics, tracing)\n  - Creating domain-specific monitoring\n\"\"\"\n\nimport asyncio\nimport json\nimport time\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any\n\nfrom amplifier_core import AmplifierSession\nfrom amplifier_core import HookResult\nfrom amplifier_foundation import load_bundle\n\n# ============================================================================\n# Performance Monitoring Hooks\n# ============================================================================\n\n\nclass PerformanceMonitor:\n    \"\"\"\n    Hook that tracks performance metrics for tools and LLM calls.\n\n    Collects:\n    - Tool execution time\n    - LLM response time\n    - Token usage\n    - Error rates\n    \"\"\"\n\n    def __init__(self):\n        self.metrics: dict[str, list[float]] = {}\n        self.tool_timings: dict[str, list[float]] = {}\n        self.token_usage: dict[str, int] = {\"input\": 0, \"output\": 0}\n        self.errors: list[dict[str, Any]] = []\n        self.start_times: dict[str, float] = {}\n\n    async def on_tool_pre(self, event: str, data: dict[str, Any]) -> HookResult:\n        \"\"\"Record tool start time.\"\"\"\n        tool_name = data.get(\"name\", \"unknown\")\n        self.start_times[f\"tool:{tool_name}\"] = time.time()\n        return HookResult(action=\"continue\")\n\n    async def on_tool_post(self, event: str, data: dict[str, Any]) -> HookResult:\n        \"\"\"Record tool completion time.\"\"\"\n        tool_name = data.get(\"name\", \"unknown\")\n        key = f\"tool:{tool_name}\"\n\n        if key in self.start_times:\n            duration = time.time() - self.start_times[key]\n            if tool_name not in self.tool_timings:\n                self.tool_timings[tool_name] = []\n            self.tool_timings[tool_name].append(duration)\n            del self.start_times[key]\n\n        return HookResult(action=\"continue\")\n\n    async def on_provider_post(self, event: str, data: dict[str, Any]) -> HookResult:\n        \"\"\"Track token usage from provider responses.\"\"\"\n        usage = data.get(\"usage\", {})\n        self.token_usage[\"input\"] += usage.get(\"input_tokens\", 0)\n        self.token_usage[\"output\"] += usage.get(\"output_tokens\", 0)\n        return HookResult(action=\"continue\")\n\n    async def on_error(self, event: str, data: dict[str, Any]) -> HookResult:\n        \"\"\"Track errors.\"\"\"\n        self.errors.append(\n            {\n                \"event\": event,\n                \"timestamp\": datetime.now().isoformat(),\n                \"data\": data,\n            }\n        )\n        return HookResult(action=\"continue\")\n\n    def print_report(self):\n        \"\"\"Print performance report.\"\"\"\n        print(\"\\n\" + \"=\" * 80)\n        print(\"\ud83d\udcca PERFORMANCE REPORT\")\n        print(\"=\" * 80)\n\n        # Tool timings\n        if self.tool_timings:\n            print(\"\\n\ud83d\udd27 Tool Performance:\")\n            for tool, timings in sorted(self.tool_timings.items()):\n                avg_time = sum(timings) / len(timings)\n                total_time = sum(timings)\n                print(f\"  {tool:30} {len(timings):3} calls, avg: {avg_time:.3f}s, total: {total_time:.3f}s\")\n\n        # Token usage\n        print(\"\\n\ud83d\udcb0 Token Usage:\")\n        print(f\"  Input tokens:  {self.token_usage['input']:,}\")\n        print(f\"  Output tokens: {self.token_usage['output']:,}\")\n        print(f\"  Total tokens:  {sum(self.token_usage.values()):,}\")\n\n        # Errors\n        if self.errors:\n            print(f\"\\n\u274c Errors: {len(self.errors)}\")\n            for error in self.errors[:3]:  # Show first 3\n                print(f\"  - {error['event']}: {error['data'].get('error', 'Unknown')}\")\n\n\nclass RateLimiter:\n    \"\"\"\n    Hook that implements rate limiting for tools.\n\n    Prevents tool spam and enforces reasonable usage patterns.\n    \"\"\"\n\n    def __init__(self, max_calls_per_minute: int = 10):\n        self.max_calls = max_calls_per_minute\n        self.call_times: list[float] = []\n\n    async def check_rate_limit(self, event: str, data: dict[str, Any]) -> HookResult:\n        \"\"\"Check if rate limit exceeded.\"\"\"\n        now = time.time()\n\n        # Remove calls older than 1 minute\n        self.call_times = [t for t in self.call_times if now - t < 60]\n\n        if len(self.call_times) >= self.max_calls:\n            print(f\"\\n\u26a0\ufe0f  RATE LIMIT: Tool {data.get('name')} blocked ({len(self.call_times)} calls in last minute)\")\n            # Could raise an error or return stop action\n            # For demo, just warn and continue\n\n        self.call_times.append(now)\n        return HookResult(action=\"continue\")\n\n\nclass CostTracker:\n    \"\"\"\n    Hook that tracks API costs in real-time.\n\n    Provides cost estimates based on token usage and model pricing.\n    \"\"\"\n\n    # Simplified pricing (per 1M tokens)\n    PRICING = {\n        \"claude-sonnet-4-5\": {\"input\": 3.00, \"output\": 15.00},\n        \"claude-haiku\": {\"input\": 0.25, \"output\": 1.25},\n        \"claude-opus\": {\"input\": 15.00, \"output\": 75.00},\n        \"gpt-4\": {\"input\": 30.00, \"output\": 60.00},\n    }\n\n    def __init__(self, model: str = \"claude-sonnet-4-5\"):\n        self.model = model\n        self.total_cost = 0.0\n        self.breakdown: dict[str, float] = {\"input\": 0.0, \"output\": 0.0}\n\n    async def track_usage(self, event: str, data: dict[str, Any]) -> HookResult:\n        \"\"\"Calculate cost from token usage.\"\"\"\n        usage = data.get(\"usage\", {})\n        input_tokens = usage.get(\"input_tokens\", 0)\n        output_tokens = usage.get(\"output_tokens\", 0)\n\n        pricing = self.PRICING.get(self.model, self.PRICING[\"claude-sonnet-4-5\"])\n\n        input_cost = (input_tokens / 1_000_000) * pricing[\"input\"]\n        output_cost = (output_tokens / 1_000_000) * pricing[\"output\"]\n\n        self.breakdown[\"input\"] += input_cost\n        self.breakdown[\"output\"] += output_cost\n        self.total_cost += input_cost + output_cost\n\n        return HookResult(action=\"continue\")\n\n    def print_summary(self):\n        \"\"\"Print cost summary.\"\"\"\n        print(f\"\\n\ud83d\udcb5 Cost Summary (Model: {self.model})\")\n        print(f\"  Input:  ${self.breakdown['input']:.4f}\")\n        print(f\"  Output: ${self.breakdown['output']:.4f}\")\n        print(f\"  Total:  ${self.total_cost:.4f}\")\n\n\n# ============================================================================\n# Audit and Compliance Hooks\n# ============================================================================\n\n\nclass AuditLogger:\n    \"\"\"\n    Hook that creates detailed audit logs for compliance.\n\n    Records all actions with timestamps, user context, and outcomes.\n    \"\"\"\n\n    def __init__(self, log_file: str | None = None):\n        self.log_file = log_file\n        self.entries: list[dict[str, Any]] = []\n\n    async def log_action(self, event: str, data: dict[str, Any]) -> HookResult:\n        \"\"\"Log an action to the audit trail.\"\"\"\n        entry = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"event\": event,\n            \"data\": self._sanitize_data(data),\n        }\n\n        self.entries.append(entry)\n\n        # Write to file if specified\n        if self.log_file:\n            with open(self.log_file, \"a\") as f:\n                f.write(json.dumps(entry) + \"\\n\")\n\n        return HookResult(action=\"continue\")\n\n    def _sanitize_data(self, data: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Remove sensitive information from logs.\"\"\"\n        # In production, implement proper PII redaction\n        sensitive_keys = [\"password\", \"api_key\", \"secret\", \"token\"]\n        return {k: v for k, v in data.items() if k.lower() not in sensitive_keys}\n\n    def print_summary(self):\n        \"\"\"Print audit summary.\"\"\"\n        print(f\"\\n\ud83d\udccb Audit Summary: {len(self.entries)} events logged\")\n        if self.log_file:\n            print(f\"   Log file: {self.log_file}\")\n\n\nclass ContentFilter:\n    \"\"\"\n    Hook that filters inappropriate content in prompts and responses.\n\n    Useful for compliance and safety.\n    \"\"\"\n\n    BLOCKED_PATTERNS = [\"password\", \"api_key\", \"secret\"]\n\n    async def filter_prompt(self, event: str, data: dict[str, Any]) -> HookResult:\n        \"\"\"Check prompts for sensitive content.\"\"\"\n        if \"prompt\" in data:\n            prompt = data[\"prompt\"].lower()\n            for pattern in self.BLOCKED_PATTERNS:\n                if pattern in prompt:\n                    print(f\"\\n\u26a0\ufe0f  CONTENT FILTER: Blocked pattern '{pattern}' in prompt\")\n                    # In production, could return HookResult(action=\"stop\")\n\n        return HookResult(action=\"continue\")\n\n\n# ============================================================================\n# Error Handling and Recovery Hooks\n# ============================================================================\n\n\nclass RetryHandler:\n    \"\"\"\n    Hook that implements automatic retry logic for transient failures.\n\n    Handles rate limits, network errors, and temporary outages.\n    \"\"\"\n\n    def __init__(self, max_retries: int = 3, backoff_factor: float = 2.0):\n        self.max_retries = max_retries\n        self.backoff_factor = backoff_factor\n        self.retry_counts: dict[str, int] = {}\n\n    async def handle_error(self, event: str, data: dict[str, Any]) -> HookResult:\n        \"\"\"Handle errors with retry logic.\"\"\"\n        error = data.get(\"error\", \"\")\n\n        # Check if this is a retryable error\n        retryable = any(pattern in str(error).lower() for pattern in [\"rate limit\", \"timeout\", \"503\", \"429\"])\n\n        if retryable:\n            key = data.get(\"name\", event)\n            retry_count = self.retry_counts.get(key, 0)\n\n            if retry_count < self.max_retries:\n                self.retry_counts[key] = retry_count + 1\n                wait_time = self.backoff_factor**retry_count\n\n                print(f\"\\n\ud83d\udd04 RETRY: Attempt {retry_count + 1}/{self.max_retries} after {wait_time:.1f}s\")\n\n                await asyncio.sleep(wait_time)\n                # Note: \"retry\" action is aspirational - Amplifier doesn't support it yet\n                # For now, continue and let the operation proceed after the backoff delay\n                return HookResult(action=\"continue\")\n\n        return HookResult(action=\"continue\")\n\n\nclass FallbackHandler:\n    \"\"\"\n    Hook that implements fallback strategies when primary approach fails.\n\n    Example: Try tool A, fall back to tool B if A fails.\n    \"\"\"\n\n    def __init__(self):\n        self.fallbacks: dict[str, str] = {\n            \"tool-web\": \"tool-bash\",  # If web fails, try bash curl\n        }\n\n    async def handle_failure(self, event: str, data: dict[str, Any]) -> HookResult:\n        \"\"\"Suggest fallback when a tool fails.\"\"\"\n        tool_name = data.get(\"name\", \"\")\n\n        if tool_name in self.fallbacks:\n            fallback = self.fallbacks[tool_name]\n            print(f\"\\n\ud83d\udca1 FALLBACK: {tool_name} failed, consider using {fallback}\")\n\n        return HookResult(action=\"continue\")\n\n\n# ============================================================================\n# Demo Scenarios\n# ============================================================================\n\n\nasync def scenario_performance_monitoring():\n    \"\"\"Demonstrate performance monitoring hooks.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"SCENARIO 1: Performance Monitoring\")\n    print(\"=\" * 80)\n    print(\"\\nTrack performance metrics during execution.\")\n    print(\"-\" * 80)\n\n    foundation_path = Path(__file__).parent.parent\n    foundation = await load_bundle(str(foundation_path))\n    mount_plan = foundation.to_mount_plan()\n\n    # Create performance monitor\n    perf_monitor = PerformanceMonitor()\n\n    # Create session and register hooks\n    session = AmplifierSession(config=mount_plan)\n    session.coordinator.hooks.register(\"tool:pre\", perf_monitor.on_tool_pre)\n    session.coordinator.hooks.register(\"tool:post\", perf_monitor.on_tool_post)\n    session.coordinator.hooks.register(\"provider:post\", perf_monitor.on_provider_post)\n    session.coordinator.hooks.register(\"*:error\", perf_monitor.on_error)\n\n    await session.initialize()\n\n    prompt = \"Use glob to find all Python files, then read the first one you find.\"\n\n    print(f\"\\n\ud83d\udcdd Prompt: {prompt}\\n\")\n\n    try:\n        await session.execute(prompt)\n        print(\"\\n\u2705 Task completed\")\n\n        # Show performance report\n        perf_monitor.print_report()\n\n    finally:\n        await session.cleanup()\n\n\nasync def scenario_cost_tracking():\n    \"\"\"Demonstrate real-time cost tracking.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"SCENARIO 2: Real-Time Cost Tracking\")\n    print(\"=\" * 80)\n    print(\"\\nTrack API costs as the session executes.\")\n    print(\"-\" * 80)\n\n    foundation_path = Path(__file__).parent.parent\n    foundation = await load_bundle(str(foundation_path))\n    mount_plan = foundation.to_mount_plan()\n\n    # Create cost tracker\n    cost_tracker = CostTracker(model=\"claude-sonnet-4-5\")\n\n    # Create session and register hooks\n    session = AmplifierSession(config=mount_plan)\n    session.coordinator.hooks.register(\"provider:post\", cost_tracker.track_usage)\n\n    await session.initialize()\n\n    prompt = \"Explain what Amplifier is and why it's useful in 3 sentences.\"\n\n    print(f\"\\n\ud83d\udcdd Prompt: {prompt}\\n\")\n\n    try:\n        await session.execute(prompt)\n        print(\"\\n\u2705 Task completed\")\n\n        # Show cost summary\n        cost_tracker.print_summary()\n\n    finally:\n        await session.cleanup()\n\n\nasync def scenario_audit_logging():\n    \"\"\"Demonstrate audit logging for compliance.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"SCENARIO 3: Audit Logging\")\n    print(\"=\" * 80)\n    print(\"\\nCreate detailed audit logs of all actions.\")\n    print(\"-\" * 80)\n\n    foundation_path = Path(__file__).parent.parent\n    foundation = await load_bundle(str(foundation_path))\n    mount_plan = foundation.to_mount_plan()\n\n    # Create audit logger\n    log_file = f\"audit_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl\"\n    audit_logger = AuditLogger(log_file=log_file)\n\n    # Create session and register hooks\n    session = AmplifierSession(config=mount_plan)\n    session.coordinator.hooks.register(\"*\", audit_logger.log_action)\n\n    await session.initialize()\n\n    prompt = \"List files in the current directory.\"\n\n    print(f\"\\n\ud83d\udcdd Prompt: {prompt}\\n\")\n\n    try:\n        await session.execute(prompt)\n        print(\"\\n\u2705 Task completed\")\n\n        # Show audit summary\n        audit_logger.print_summary()\n\n    finally:\n        await session.cleanup()\n\n\nasync def scenario_composed_hooks():\n    \"\"\"Demonstrate composing multiple hooks together.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"SCENARIO 4: Composed Hooks\")\n    print(\"=\" * 80)\n    print(\"\\nCombine multiple hooks for comprehensive monitoring.\")\n    print(\"-\" * 80)\n\n    foundation_path = Path(__file__).parent.parent\n    foundation = await load_bundle(str(foundation_path))\n    mount_plan = foundation.to_mount_plan()\n\n    # Create multiple hooks\n    perf_monitor = PerformanceMonitor()\n    cost_tracker = CostTracker()\n    rate_limiter = RateLimiter(max_calls_per_minute=10)\n\n    # Create session and register all hooks\n    session = AmplifierSession(config=mount_plan)\n\n    # Performance monitoring\n    session.coordinator.hooks.register(\"tool:pre\", perf_monitor.on_tool_pre)\n    session.coordinator.hooks.register(\"tool:post\", perf_monitor.on_tool_post)\n    session.coordinator.hooks.register(\"provider:post\", perf_monitor.on_provider_post)\n\n    # Cost tracking\n    session.coordinator.hooks.register(\"provider:post\", cost_tracker.track_usage)\n\n    # Rate limiting\n    session.coordinator.hooks.register(\"tool:pre\", rate_limiter.check_rate_limit)\n\n    await session.initialize()\n\n    prompt = \"Find all Python files and show me their sizes.\"\n\n    print(f\"\\n\ud83d\udcdd Prompt: {prompt}\\n\")\n\n    try:\n        await session.execute(prompt)\n        print(\"\\n\u2705 Task completed\")\n\n        # Show all reports\n        perf_monitor.print_report()\n        cost_tracker.print_summary()\n\n    finally:\n        await session.cleanup()\n\n\n# ============================================================================\n# Interactive Menu\n# ============================================================================\n\n\nasync def main():\n    \"\"\"Run interactive demo menu.\"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"\ud83c\udfa3 Custom Hook Library\")\n    print(\"=\" * 80)\n    print(\"\\nVALUE: Build reusable hooks for production applications\")\n    print(\"AUDIENCE: Developers building with Amplifier\")\n    print(\"\\nWhat this demonstrates:\")\n    print(\"  - Performance monitoring and metrics\")\n    print(\"  - Real-time cost tracking\")\n    print(\"  - Audit logging for compliance\")\n    print(\"  - Composing multiple hooks\")\n\n    scenarios = [\n        (\"Performance Monitoring\", scenario_performance_monitoring),\n        (\"Cost Tracking\", scenario_cost_tracking),\n        (\"Audit Logging\", scenario_audit_logging),\n        (\"Composed Hooks (all together)\", scenario_composed_hooks),\n    ]\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"Choose a scenario:\")\n    print(\"=\" * 80)\n    for i, (name, _) in enumerate(scenarios, 1):\n        print(f\"  {i}. {name}\")\n    print(\"  q. Quit\")\n    print(\"-\" * 80)\n\n    choice = input(\"\\nYour choice: \").strip().lower()\n\n    if choice == \"q\":\n        print(\"\\n\ud83d\udc4b Goodbye!\")\n        return\n\n    try:\n        idx = int(choice) - 1\n        if 0 <= idx < len(scenarios):\n            _, scenario_func = scenarios[idx]\n            await scenario_func()\n        else:\n            print(\"\\n\u274c Invalid choice\")\n    except ValueError:\n        print(\"\\n\u274c Invalid choice\")\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"\ud83d\udca1 KEY TAKEAWAYS\")\n    print(\"=\" * 80)\n    print(\"\"\"\n1. **Hooks are Middleware**: Cross-cutting concerns without modifying core logic\n2. **Composable**: Combine multiple hooks for comprehensive monitoring\n3. **Event-Driven**: React to specific events in the execution flow\n4. **Production-Ready**: Patterns for metrics, costs, audit logs, errors\n\n**Common hook patterns:**\n- Performance monitoring (timing, resource usage)\n- Cost tracking (token usage, API costs)\n- Audit logging (compliance, debugging)\n- Rate limiting (prevent abuse)\n- Error handling (retry, fallback)\n- Content filtering (safety, compliance)\n\n**Implementation tips:**\n- Keep hooks focused (single responsibility)\n- Make hooks reusable across projects\n- Use async/await properly\n- Always return HookResult\n- Test hooks independently\n- Document expected events and data format\n\"\"\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n",
      "advancedOptions": {
        "provider": [
          "anthropic-sonnet",
          "anthropic-opus",
          "openai-gpt4"
        ],
        "streaming": false,
        "hooks": []
      }
    }
  },
  "execution": {
    "requiresInput": true,
    "defaultPrompt": null,
    "estimatedDuration": "2-5 seconds",
    "prerequisites": [
      "ANTHROPIC_API_KEY environment variable"
    ]
  }
}